{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why some resturant are successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Since everyone loves food (presumably), the ultimate end goal of this homework will determine the success of restaurant. there are various of restaurants in the world but some are successful and others are not. We want to use the data from yelp to analysis the insight of what is the definition of the successful restaurant. \n",
    "\n",
    "We assume that the score of a restaurant on Yelp and reflect the degree of success of this restaurant. We want to use the info from the restaurants such as its location, menu, environment, and kinds of attributes from those websites and analyze the factors which contribute to the success of a restaurant. Then we could try to use this function generated to evaluate the future business of a new restaurant and try to give some advice on how to make them become better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Solutions\n",
    "\n",
    "To tell why some restaurants are successful, we have some steps to do.\n",
    "\n",
    "First is to give the definition of the ‘success’ of certain restaurant. We assume that the score could reflect the degree of success but the detail of how to reflect needs to be determined by doing some analytics. We need to use the distribution of score to decide which score is the threshold of successful restaurants. \n",
    "\n",
    "Second, when we have decided how to reflect the success degree by the score, then we can divide the restaurant data into two parts and dig into the details. This is the main part of the project that needs to be dealt with because there are many things to be decided here. Like which attributes may contribute to the success of restaurant? How to measure these attributes like location? What the granularity should be picked for these attributes?\n",
    "\n",
    "Last but not least, we need to visualize the result make some conclusion based on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Definition of Success\n",
    "\n",
    "The first part of out project is to get the definition of success. To get this done, we must first scrap the data from Yelp using the techs we learned before and do some simple analytic based on this data.\n",
    "\n",
    "Here are some basic libairies that will be used during this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup library imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# import yelp client library\n",
    "from yelp.client import Client\n",
    "from yelp.oauth1_authenticator import Oauth1Authenticator\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn # or alternatively plt.style.use('ggplot') for a similar look\n",
    "\n",
    "matplotlib.rc(\"figure\", figsize=(8,6))\n",
    "matplotlib.rc(\"axes\", labelsize=16, titlesize=16)\n",
    "matplotlib.rc(\"xtick\", labelsize=14)\n",
    "matplotlib.rc(\"ytick\", labelsize=14)\n",
    "matplotlib.rc(\"legend\", fontsize=14)\n",
    "matplotlib.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data\n",
    "\n",
    "The first step of data science project is to get the data for later science use. Here, we use the both Yelp API and scraper to help get all the data needed for our project. \n",
    "\n",
    "Yelp API is used for get the restaurant attributes data. It will return all the things in Json format which has very food format and detailed and correct information. Scraper is used for getting the review and rating score of certain restaurant by parsing the webpage. Scraper could get all the data which could be accessed by user. But the correctness could be lower beacause it is parsed by us.\n",
    "\n",
    "Before we used Yelp API, we must first autheticate with the authentication API of Yelp. We could use the authenticate function here to authenticate with the Yelp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def authenticate(config_filepath):\n",
    "    \"\"\"\n",
    "    Create an authenticated yelp-python client.\n",
    "\n",
    "    Args:\n",
    "        config_filepath (string): relative path (from this file) to a file with your Yelp credentials\n",
    "\n",
    "    Returns:\n",
    "        client (yelp.client.Client): authenticated instance of a yelp.Client\n",
    "    \"\"\"\n",
    "    import yelp_auth as ya\n",
    "    auth = Oauth1Authenticator(\n",
    "        consumer_key=ya.CONSUMER_KEY,\n",
    "        consumer_secret=ya.CONSUMER_SECRET,\n",
    "        token=ya.TOKEN,\n",
    "        token_secret=ya.TOKEN_SECRET\n",
    "    )\n",
    "    return Client(auth)\n",
    "client = authenticate('yelp_auth.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Using yelp API - Aquire all of the restaurants in Mountain View city\n",
    "\n",
    "After we authenticate with Yelp, then we can use the Yelp API to get data that may be used in the analytics. The input object will be structured as the [sample](https://www.yelp.com/developers/documentation/v2/search_api#sampleResponse) on the Yelp API page.\n",
    "\n",
    "Here, we want to make analytics on all the restaurants in one city. In our project, we want to use the city 'Mountian View, CA' as the target city. And during the implementation, we found that if we fetch the data with city as parameter, we won't get correct data because there are too many cities with the same name in United States. So we use the zip code as the input parameter. In this way, we could get the data from correct city.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geosearch_py import GeoSearch\n",
    "import numpy as np\n",
    "import itertools\n",
    "chunk_size = 4\n",
    "\n",
    "def authenticate_geoclient(config_path):\n",
    "    with open(config_path) as f:\n",
    "        key = f.read().strip()\n",
    "    return GeoSearch(key)\n",
    "\n",
    "def get_geo_bbox(client, location):\n",
    "    bbox = client.geo_bounds(location)\n",
    "    lats = np.linspace(*sorted([bbox['northeast']['lat'], bbox['southwest']['lat']]), num=chunk_size)\n",
    "    lons = np.linspace(*sorted([bbox['northeast']['lng'], bbox['southwest']['lng']]), num=chunk_size)\n",
    "    return [(lats[i+1], lons[j], lats[i], lons[j+1]) for i in range(chunk_size-1) for j in range(chunk_size-1)]\n",
    "\n",
    "def get_restaurants_in_city(client, query):\n",
    "    \"\"\"\n",
    "    Retrieve ALL the restaurants on Yelp for a given query.\n",
    "\n",
    "    Args:\n",
    "        query (string): Search term\n",
    " Returns:\n",
    "        results (list): list of yelp.obj.business.Business objects\n",
    "    \"\"\"\n",
    "    bbox = get_geo_bbox(authenticate_geoclient('geoclient'), query)\n",
    "    size = 20\n",
    "    ret = []\n",
    "    for box in bbox:\n",
    "        param = {'term':'food', 'limit':size, 'offset': 0}\n",
    "        res = client.search_by_bounding_box(*box, **param)\n",
    "        all_rest = res.businesses\n",
    "        total = res.total - size\n",
    "        offset = size\n",
    "        while total > 0:\n",
    "            time.sleep(0.2)\n",
    "            param['offset'] = offset\n",
    "            try:\n",
    "                businesses = client.search(query, **param).businesses\n",
    "            except:\n",
    "                if len(all_rest) * 1.0 / total > 0.5:\n",
    "                    return all_rest\n",
    "                return all_rest\n",
    "            all_rest += businesses\n",
    "            total -= len(businesses)\n",
    "            offset += size\n",
    "        ret += all_rest\n",
    "    return ret\n",
    "\n",
    "data = []\n",
    "data = get_restaurants_in_city(client, 'Mountain View, CA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse web pages - get more data like reviews and prices\n",
    "\n",
    "After we get the distribution of rating, in other words, the definition of success. Then we can deal with the source data. The first data we want to analyze is the review data. Review data can only be fetched by parsing the page.\n",
    "\n",
    "We want to implement a function with such input and output. The input is the url of restaurant and we want the get the return as a json with contains some infomation like review_id, text which is good at future analysis.\n",
    "\n",
    "```python\n",
    "# Input:\n",
    "    restuanrant url\n",
    "# Output\n",
    "\n",
    "[{\n",
    "    'review_id': '12345'\n",
    "    'user_id': '6789'\n",
    "    'rating': 4.7\n",
    "    'date': '2016-01-23'\n",
    "    'text': \"Wonderful!\"\n",
    "},{}...]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Extract all reviews for each restuarant\n",
    "After we parse the page, then we can try to get the yelp reivews for this restaurant. This is the same as we did in homework. To make notebook more readable we extract this part of code out as helper functions.\n",
    "### Extract price range for each restuarant\n",
    "Since the API does not provide this info, we need to parse the web page which is similar as getting reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crawl_web_page import extract_all_reviews, extract_all_prices\n",
    "urls = {f.id: f.url for f in data}\n",
    "extract_all_reviews(urls)\n",
    "extract_all_prices(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Draw the distribution\n",
    "\n",
    "Now, we have got all the data of restaurants located in Mountain View, CA. Then we want to get the distribution of ratings of these restaurants. Before we do it, we could first draw the distribution of ratings. \n",
    "\n",
    "Here we use the the plt to draw the image of the distribution of the rating score. From the image, we could see the distribution may apply to a normal distribution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = [d.rating for d in data]\n",
    "plt.hist(ratings, bins=50);\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
